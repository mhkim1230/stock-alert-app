#!/usr/bin/env python3
"""
ë„¤ì´ë²„ íŒŒì‹± ì „ìš© API ì„œë²„
ì‹¤ì œ ë„¤ì´ë²„ì—ì„œ ì£¼ì‹/í™˜ìœ¨ ë°ì´í„°ë¥¼ íŒŒì‹±í•´ì„œ ì œê³µ
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import requests
from bs4 import BeautifulSoup, Tag
import re
import uvicorn
import json
from urllib.parse import quote

app = FastAPI(title="ë„¤ì´ë²„ ê¸ˆìœµ íŒŒì‹± API")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë„¤ì´ë²„ ê²€ìƒ‰ í—¤ë” (ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ê²Œ)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

@app.get("/")
async def root():
    return {"message": "ğŸ”¥ ë„¤ì´ë²„ ê¸ˆìœµ ì‹¤ì‹œê°„ íŒŒì‹± API", "status": "running"}

@app.get("/health")
async def health():
    return {"status": "healthy", "service": "naver_parsing"}

@app.get("/naver/stocks/search/{query}")
async def search_stocks(query: str):
    """ì‹¤ì œ ë„¤ì´ë²„ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ì£¼ì‹ ì •ë³´ íŒŒì‹±"""
    print(f"ğŸ” ì£¼ì‹ ê²€ìƒ‰: {query}")
    
    try:
        stocks = []
        
        # ë°©ë²• 1: ë„¤ì´ë²„ ì¼ë°˜ ê²€ìƒ‰
        search_url = f"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query={quote(query)}"
        print(f"ğŸ“¡ ì¼ë°˜ ê²€ìƒ‰ URL: {search_url}")
        
        response = requests.get(search_url, headers=HEADERS, timeout=10)
        print(f"ğŸ“¡ ì¼ë°˜ ê²€ìƒ‰ ì‘ë‹µ: {response.status_code}")
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ì£¼ì‹ ê´€ë ¨ ë§í¬ ì°¾ê¸°
            links = soup.find_all('a', href=re.compile(r'finance\.naver\.com'))
            print(f"ğŸ”— ë°œê²¬ëœ ê¸ˆìœµ ë§í¬ ìˆ˜: {len(links)}")
            
            for link in links[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                try:
                    href = link.get('href') or ''  # None ëŒ€ì‹  ë¹ˆ ë¬¸ìì—´ ì‚¬ìš©
                    if 'item/main.naver' in href:
                        # ì¢…ëª© ì •ë³´ ì¶”ì¶œ
                        code_match = re.search(r'code=(\d+)', href)
                        if code_match:
                            symbol = code_match.group(1)
                            name = link.get_text().strip()
                            
                            # ì‹¤ì œ ì¢…ëª© í˜ì´ì§€ì—ì„œ ê°€ê²© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                            stock_info = await get_stock_detail(symbol, name)
                            if stock_info:
                                stocks.append(stock_info)
                except Exception as e:
                    print(f"âš ï¸ ë§í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
        
        # ë°©ë²• 2: ë„¤ì´ë²„ ê¸ˆìœµ ì§ì ‘ ê²€ìƒ‰
        if len(stocks) == 0:
            print("ğŸ” ë„¤ì´ë²„ ê¸ˆìœµ ì§ì ‘ ê²€ìƒ‰ ì‹œë„")
            finance_search_url = f"https://finance.naver.com/search/searchList.naver?query={quote(query)}"
            print(f"ğŸ“¡ ê¸ˆìœµ ê²€ìƒ‰ URL: {finance_search_url}")
            
            try:
                finance_response = requests.get(finance_search_url, headers=HEADERS, timeout=10)
                print(f"ğŸ“¡ ê¸ˆìœµ ê²€ìƒ‰ ì‘ë‹µ: {finance_response.status_code}")
                
                if finance_response.status_code == 200:
                    finance_soup = BeautifulSoup(finance_response.text, 'html.parser')
                    
                    # ê²€ìƒ‰ ê²°ê³¼ í…Œì´ë¸”ì—ì„œ ì¢…ëª© ì°¾ê¸°
                    result_rows = finance_soup.find_all('tr')
                    for row in result_rows[:5]:  # ìƒìœ„ 5ê°œ
                        cells = row.find_all('td')
                        if len(cells) >= 2:
                            # ì¢…ëª©ëª…ê³¼ ì½”ë“œ ì¶”ì¶œ ì‹œë„
                            for cell in cells:
                                link = cell.find('a', href=re.compile(r'code=\d+'))
                                if link:
                                    href = link.get('href')
                                    code_match = re.search(r'code=(\d+)', href)
                                    if code_match:
                                        symbol = code_match.group(1)
                                        name = link.get_text().strip()
                                        
                                        print(f"ğŸ¯ ê¸ˆìœµ ê²€ìƒ‰ì—ì„œ ë°œê²¬: {name} ({symbol})")
                                        
                                        # ì¤‘ë³µ ì²´í¬
                                        if not any(s['symbol'] == symbol for s in stocks):
                                            stock_info = await get_stock_detail(symbol, name)
                                            if stock_info:
                                                stocks.append(stock_info)
                                        break
            except Exception as e:
                print(f"âš ï¸ ë„¤ì´ë²„ ê¸ˆìœµ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # ë°©ë²• 3: í•´ì™¸ ì£¼ì‹ ê²€ìƒ‰ (ë„¤ì´ë²„ ëª¨ë°”ì¼)
        if len(stocks) == 0:
            print("ğŸ” í•´ì™¸ ì£¼ì‹ ê²€ìƒ‰ ì‹œë„")
            try:
                # ë„¤ì´ë²„ ëª¨ë°”ì¼ í•´ì™¸ ì£¼ì‹ ê²€ìƒ‰
                world_search_url = f"https://m.stock.naver.com/api/search/stock?query={quote(query)}"
                print(f"ğŸ“¡ í•´ì™¸ ì£¼ì‹ API URL: {world_search_url}")
                
                world_response = requests.get(world_search_url, headers=HEADERS, timeout=10)
                print(f"ğŸ“¡ í•´ì™¸ ì£¼ì‹ API ì‘ë‹µ: {world_response.status_code}")
                
                if world_response.status_code == 200:
                    try:
                        world_data = world_response.json()
                        print(f"ğŸ” í•´ì™¸ ì£¼ì‹ API ë°ì´í„°: {world_data}")
                        
                        # API ì‘ë‹µì—ì„œ í•´ì™¸ ì£¼ì‹ ì°¾ê¸°
                        if 'result' in world_data and 'items' in world_data['result']:
                            for item in world_data['result']['items'][:3]:
                                if item.get('market') in ['NASDAQ', 'NYSE', 'AMEX']:
                                    symbol = item.get('code', '')
                                    name = item.get('name', '')
                                    
                                    if symbol and name:
                                        print(f"ğŸ¯ í•´ì™¸ ì£¼ì‹ ë°œê²¬: {name} ({symbol})")
                                        
                                        # í•´ì™¸ ì£¼ì‹ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                                        world_stock = await get_world_stock_detail(symbol, name)
                                        if world_stock:
                                            stocks.append(world_stock)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ í•´ì™¸ ì£¼ì‹ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        
                        # APIê°€ JSONì´ ì•„ë‹ ë•Œ HTML íŒŒì‹± ì‹œë„
                        world_soup = BeautifulSoup(world_response.text, 'html.parser')
                        
                        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•´ì™¸ ì£¼ì‹ ë§í¬ ì°¾ê¸°
                        world_links = world_soup.find_all('a', href=re.compile(r'worldstock/stock/[A-Z\.]+'))
                        print(f"ğŸ”— í•´ì™¸ ì£¼ì‹ ë§í¬ ìˆ˜: {len(world_links)}")
                        
                        for link in world_links[:3]:
                            if isinstance(link, Tag):  # Tag ê°ì²´ë§Œ ì²˜ë¦¬
                                try:
                                    href = link.get('href')
                                    symbol_match = re.search(r'worldstock/stock/([A-Z\.]+)', href)
                                    if symbol_match:
                                        symbol = symbol_match.group(1)
                                        name = link.get_text().strip()
                                        
                                        print(f"ğŸ¯ í•´ì™¸ ì£¼ì‹ ë§í¬ì—ì„œ ë°œê²¬: {name} ({symbol})")
                                        
                                        world_stock = await get_world_stock_detail(symbol, name)
                                        if world_stock:
                                            stocks.append(world_stock)
                                except Exception as e:
                                    print(f"âš ï¸ í•´ì™¸ ì£¼ì‹ ë§í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                                continue
                                
            except Exception as e:
                print(f"âš ï¸ í•´ì™¸ ì£¼ì‹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # ë°©ë²• 4: ë„¤ì´ë²„ ì£¼ì‹ ì „ìš© ê²€ìƒ‰ (í•´ì™¸ ì£¼ì‹ í¬í•¨)
        if len(stocks) == 0:
            print("ğŸ” ë„¤ì´ë²„ ì£¼ì‹ ì „ìš© ê²€ìƒ‰ ì‹œë„")
            try:
                stock_search_url = f"https://search.naver.com/search.naver?where=stock&query={quote(query)}"
                print(f"ğŸ“¡ ì£¼ì‹ ì „ìš© ê²€ìƒ‰ URL: {stock_search_url}")
                
                stock_response = requests.get(stock_search_url, headers=HEADERS, timeout=10)
                print(f"ğŸ“¡ ì£¼ì‹ ì „ìš© ê²€ìƒ‰ ì‘ë‹µ: {stock_response.status_code}")
                
                if stock_response.status_code == 200:
                    # JavaScript ë³€ìˆ˜ì—ì„œ ì‹¤ì‹œê°„ ì£¼ì‹ ë°ì´í„° ì¶”ì¶œ
                    stock_data = await extract_stock_data_from_js(stock_response.text, query)
                    if stock_data:
                        stocks.append(stock_data)
                        print(f"ğŸ¯ ì£¼ì‹ ì „ìš© ê²€ìƒ‰ì—ì„œ ë°œê²¬: {stock_data['name']} (${stock_data['current_price']})")
                        
            except Exception as e:
                print(f"âš ï¸ ì£¼ì‹ ì „ìš© ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # í•˜ë“œì½”ë”© ê¸ˆì§€ - ì‹¤ì œ ê²€ìƒ‰ë§Œ ì‚¬ìš©
        print("ğŸ” í•˜ë“œì½”ë”© ì—†ì´ ì‹¤ì œ ê²€ìƒ‰ë§Œ ì‚¬ìš©")
        
        # í•˜ë“œì½”ë”© ë§¤ì¹­ ì œê±° - ì‹¤ì œ ê²€ìƒ‰ë§Œ ì‚¬ìš©
        
        print(f"âœ… ìµœì¢… ê²€ìƒ‰ ì™„ë£Œ: {len(stocks)}ê°œ ì¢…ëª© ë°œê²¬")
        return {"results": stocks, "query": query}
        
    except Exception as e:
        print(f"âŒ ì£¼ì‹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì£¼ì‹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

async def get_stock_detail(symbol: str, name: str):
    """ì¢…ëª© ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œ ë„¤ì´ë²„ íŒŒì‹±)"""
    print(f"ğŸ” ì¢…ëª© ìƒì„¸ ì¡°íšŒ: {symbol} ({name})")
    
    try:
        detail_url = f"https://finance.naver.com/item/main.naver?code={symbol}"
        print(f"ğŸ“¡ URL: {detail_url}")
        
        response = requests.get(detail_url, headers=HEADERS, timeout=10)
        print(f"ğŸ“¡ ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ HTTP ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return None
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë””ë²„ê¹…: HTML ìƒ˜í”Œ ì¶œë ¥ (ë” ë§ì´)
        print("ğŸ” HTML ìƒ˜í”Œ:")
        print(response.text[:2000])
        print("=" * 50)
        
        # ê°€ê²© íŒŒì‹± - ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„
        current_price = 0
        
        # ë°©ë²• 1: ëª¨ë“  ìˆ«ìê°€ í¬í•¨ëœ ìš”ì†Œ ì°¾ê¸°
        print("ğŸ” ë°©ë²•1: ëª¨ë“  span.blind ìš”ì†Œ í™•ì¸")
        blind_elements = soup.find_all('span', class_='blind')
        print(f"ğŸ” ì´ {len(blind_elements)}ê°œì˜ blind ìš”ì†Œ ë°œê²¬")
        
        for i, elem in enumerate(blind_elements):
            text = elem.get_text().strip().replace(',', '')
            print(f"ğŸ” blind[{i}]: '{elem.get_text().strip()}'")
            
            # ìˆ«ìì¸ì§€ í™•ì¸í•˜ê³  í•©ë¦¬ì ì¸ ì£¼ê°€ ë²”ìœ„ì¸ì§€ ì²´í¬
            try:
                if text.replace(',', '').replace('.', '').isdigit():
                    price_val = float(text)
                    if 100 <= price_val <= 500000:  # í•©ë¦¬ì ì¸ ì£¼ê°€ ë²”ìœ„
                        print(f"âœ… ê°€ê²© í›„ë³´ ë°œê²¬: {price_val} (blind[{i}])")
                        if current_price == 0:  # ì²« ë²ˆì§¸ í•©ë¦¬ì ì¸ ê°€ê²© ì‚¬ìš©
                            current_price = price_val
            except:
                continue
                
        # ë°©ë²• 2: ë‹¤ë¥¸ CSS ì„ íƒìë“¤ ì‹œë„
        print("ğŸ” ë°©ë²•2: ë‹¤ë¥¸ CSS ì„ íƒì ì‹œë„")
        
        # ì¼ë°˜ì ì¸ ì£¼ê°€ í‘œì‹œ ì„ íƒìë“¤
        price_selectors = [
            'span.code',
            'span.num',
            'td.num',
            'span.tah.p11',
            'em.num',
            'strong.num',
            '.today .blind',
            '.no_today .blind'
        ]
        
        for selector in price_selectors:
            elements = soup.select(selector)
            print(f"ğŸ” {selector}: {len(elements)}ê°œ ë°œê²¬")
            for elem in elements:
                text = elem.get_text().strip()
                print(f"  - '{text}'")
                try:
                    clean_text = text.replace(',', '').replace('ì›', '')
                    if clean_text.replace('.', '').isdigit():
                        price_val = float(clean_text)
                        if 100 <= price_val <= 500000 and current_price == 0:
                            current_price = price_val
                            print(f"âœ… ê°€ê²© ë°œê²¬ ({selector}): {price_val}")
                except:
                    continue
        
        # ë°©ë²• 3: í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
        print("ğŸ” ë°©ë²•3: í…Œì´ë¸” ë°ì´í„° í™•ì¸")
        tables = soup.find_all('table')
        print(f"ğŸ” {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
        
        for table_idx, table in enumerate(tables):
            if hasattr(table, 'find_all'):  # find_all ë©”ì„œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                try:
                    rows = table.find_all('tr')
                    for row_idx, row in enumerate(rows):
                        if hasattr(row, 'find_all'):  # find_all ë©”ì„œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                            try:
                                cells = row.find_all(['td', 'th'])
                                for cell_idx, cell in enumerate(cells):
                                    text = cell.get_text().strip()
                                    if ',' in text and text.replace(',', '').replace('ì›', '').isdigit():
                                        try:
                                            price_val = float(text.replace(',', '').replace('ì›', ''))
                                            if 100 <= price_val <= 500000:
                                                print(f"ğŸ” í…Œì´ë¸”[{table_idx}][{row_idx}][{cell_idx}]: {text} -> {price_val}")
                                                if current_price == 0:
                                                    current_price = price_val
                                            break
                                        except:
                                            continue
                            except:
                                continue
                except:
                    continue
        
        print(f"ğŸ” ìµœì¢… íŒŒì‹±ëœ ê°€ê²©: {current_price}")
        
        # ë³€ë™ë¥  íŒŒì‹±
        change_percent = 0
        
        print("ğŸ” ë³€ë™ë¥  íŒŒì‹± ì‹œë„")
        
        # ë°©ë²• 1: % í¬í•¨ëœ í…ìŠ¤íŠ¸ ì°¾ê¸°
        percent_texts = soup.find_all(string=re.compile(r'\d+\.\d+%'))
        print(f"ğŸ” % í…ìŠ¤íŠ¸ {len(percent_texts)}ê°œ ë°œê²¬:")
        for text in percent_texts:
            print(f"  - '{text.strip()}'")
            try:
                percent_match = re.search(r'(\d+\.\d+)%', text)
                if percent_match:
                    change_percent = float(percent_match.group(1))
                    print(f"âœ… ë³€ë™ë¥  ë°œê²¬: {change_percent}%")
                    break
            except:
                continue
        
        # ê²°ê³¼ ë¦¬í„´
        result = {
            'symbol': symbol,
            'name': name,
            'name_kr': name,
            'current_price': current_price,
            'change_percent': change_percent,
            'market': 'KOSPI',
            'source': 'naver_real_parsing'
        }
        
        print(f"âœ… ìµœì¢… ê²°ê³¼: {result}")
        return result
        
    except Exception as e:
        print(f"âŒ ì¢…ëª© ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return None

@app.get("/naver/currency/rate/{from_currency}/{to_currency}")
async def get_currency_rate(from_currency: str, to_currency: str):
    """ë„¤ì´ë²„ì—ì„œ í™˜ìœ¨ ì •ë³´ íŒŒì‹±"""
    print(f"ğŸ’± í™˜ìœ¨ ì¡°íšŒ: {from_currency}/{to_currency}")
    
    try:
        # ë„¤ì´ë²„ í™˜ìœ¨ í˜ì´ì§€ URL
        currency_url = f"https://finance.naver.com/marketindex/exchangeDetail.naver?marketindexCd=FX_{from_currency}{to_currency}"
        print(f"ğŸ“¡ í™˜ìœ¨ URL: {currency_url}")
        
        response = requests.get(currency_url, headers=HEADERS, timeout=10)
        print(f"ğŸ“¡ í™˜ìœ¨ ì‘ë‹µ: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ í™˜ìœ¨ HTTP ì˜¤ë¥˜: {response.status_code}")
            return {"error": f"í™˜ìœ¨ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}"}
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë””ë²„ê¹…: HTML ìƒ˜í”Œ ì¶œë ¥
        print("ğŸ” í™˜ìœ¨ HTML ìƒ˜í”Œ:")
        print(response.text[:1500])
        print("=" * 50)
        
        # í™˜ìœ¨ íŒŒì‹± - ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„
        rate = 0
        
        # ë°©ë²• 1: span.blindì—ì„œ ì°¾ê¸°
        blind_elements = soup.find_all('span', class_='blind')
        print(f"ğŸ” í™˜ìœ¨ span.blind ìš”ì†Œ {len(blind_elements)}ê°œ:")
        for i, elem in enumerate(blind_elements):
            text = elem.get_text().strip()
            print(f"  [{i}] '{text}'")
            try:
                # ìˆ«ìì™€ ì ë§Œ ìˆëŠ” í˜•íƒœ (í™˜ìœ¨ í˜•íƒœ)
                if re.match(r'^\d{1,4}\.\d+$', text.replace(',', '')):
                    rate_val = float(text.replace(',', ''))
                    if 1000 <= rate_val <= 2000:  # USD/KRW í•©ë¦¬ì  ë²”ìœ„
                        print(f"âœ… í™˜ìœ¨ ë°œê²¬: {rate_val}")
                        rate = rate_val
                        break
            except:
                continue
        
        # ë°©ë²• 2: í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
        if rate == 0:
            print("ğŸ” í™˜ìœ¨ í…Œì´ë¸” ë°©ë²•:")
            tables = soup.find_all('table')
            for table_idx, table in enumerate(tables):
                rows = table.find_all('tr')
                for row_idx, row in enumerate(rows):
                    cells = row.find_all(['td', 'th'])
                    for cell_idx, cell in enumerate(cells):
                        text = cell.get_text().strip()
                        # í™˜ìœ¨ í˜•íƒœ ìˆ«ì ì°¾ê¸°
                        if re.match(r'^\d{1,4}\.\d+$', text.replace(',', '')):
                            try:
                                rate_val = float(text.replace(',', ''))
                                if 1000 <= rate_val <= 2000:
                                    print(f"ğŸ” í™˜ìœ¨ í…Œì´ë¸”[{table_idx}][{row_idx}][{cell_idx}]: {text} -> {rate_val}")
                                    rate = rate_val
                                    break
                            except:
                                continue
        
        print(f"âœ… ìµœì¢… í™˜ìœ¨: {from_currency}/{to_currency} = {rate}")
        
        if rate > 0:
            return {
                "pair": f"{from_currency}/{to_currency}",
                "rate": rate,
                "source": "naver_real_parsing"
            }
        else:
            return {"error": "í™˜ìœ¨ íŒŒì‹± ì‹¤íŒ¨"}
            
    except Exception as e:
        print(f"âŒ í™˜ìœ¨ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return {"error": f"í™˜ìœ¨ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}

@app.get("/naver/worldstock/{symbol}")
async def get_world_stock_direct(symbol: str):
    """í•´ì™¸ ì£¼ì‹ ì§ì ‘ ì¡°íšŒ (í…ŒìŠ¤íŠ¸ìš©)"""
    print(f"ğŸŒ í•´ì™¸ ì£¼ì‹ ì§ì ‘ ì¡°íšŒ: {symbol}")
    
    try:
        result = await get_world_stock_detail(symbol, symbol)
        if result:
            return {"result": result}
        else:
            return {"error": f"í•´ì™¸ ì£¼ì‹ {symbol} ì¡°íšŒ ì‹¤íŒ¨"}
    except Exception as e:
        print(f"âŒ í•´ì™¸ ì£¼ì‹ ì§ì ‘ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return {"error": f"í•´ì™¸ ì£¼ì‹ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}

async def get_world_stock_detail(symbol: str, name: str):
    """í•´ì™¸ ì£¼ì‹ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë„¤ì´ë²„ ëª¨ë°”ì¼)"""
    print(f"ğŸŒ í•´ì™¸ ì£¼ì‹ ìƒì„¸ ì¡°íšŒ: {symbol} ({name})")
    
    try:
        # ì‚¬ìš©ì ì œê³µ ì •í™•í•œ URL íŒ¨í„´ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„
        urls_to_try = [
            f"https://m.stock.naver.com/worldstock/stock/{symbol}.O/total",  # NASDAQ (ì—”ë¹„ë””ì•„ìš©)
            f"https://m.stock.naver.com/worldstock/stock/{symbol}.N/total",  # NYSE  
            f"https://m.stock.naver.com/worldstock/stock/{symbol}/total",    # ì ‘ë¯¸ì‚¬ ì—†ìŒ (ê¸°ì¡´ ë°©ì‹)
            f"https://m.stock.naver.com/worldstock/stock/{symbol}.Q/total",  # NASDAQ Global Select
        ]
        
        soup = None
        successful_url = None
        
        for attempt, detail_url in enumerate(urls_to_try, 1):
            print(f"ğŸ“¡ í•´ì™¸ ì£¼ì‹ URL ì‹œë„ {attempt}/{len(urls_to_try)}: {detail_url}")
            
            response = requests.get(detail_url, headers=HEADERS, timeout=10)
            print(f"ğŸ“¡ í•´ì™¸ ì£¼ì‹ ì‘ë‹µ {attempt}: {response.status_code}")
            
            if response.status_code == 200:
                print(f"âœ… ì„±ê³µí•œ URL: {detail_url}")
                temp_soup = BeautifulSoup(response.text, 'html.parser')
                
                # ì‹¤ì œ ì£¼ì‹ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                if _validate_world_stock_page(temp_soup):
                    print(f"âœ… ìœ íš¨í•œ í•´ì™¸ì£¼ì‹ í˜ì´ì§€ ë°œê²¬!")
                    soup = temp_soup
                    successful_url = detail_url
                    break
                else:
                    print(f"âš ï¸ í˜ì´ì§€ëŠ” ì—´ë ¸ì§€ë§Œ ì£¼ì‹ ë°ì´í„° ì—†ìŒ")
                    continue
            else:
                print(f"âŒ í•´ì™¸ ì£¼ì‹ HTTP ì˜¤ë¥˜ {attempt}: {response.status_code}")
                continue
        else:
            # ëª¨ë“  URL ì‹œë„ ì‹¤íŒ¨
            print(f"âŒ ëª¨ë“  í•´ì™¸ ì£¼ì‹ URL ì‹œë„ ì‹¤íŒ¨: {symbol}")
            return None
        
        # ì‹¤ì œ ì£¼ì‹ ë°ì´í„° íŒŒì‹±
        current_price = 0
        change_percent = 0
        
        # ê°€ê²© íŒŒì‹±
        print("ğŸ” í•´ì™¸ ì£¼ì‹ ê°€ê²© íŒŒì‹± ì‹œì‘")
        
        # ë°©ë²• 1: ê°€ê²© CSS ì„ íƒìë“¤
        price_selectors = [
            'span.price', 'span.num', '.price_area .num', '.today_price', 
            '.current_price', 'em.num', 'strong.num', '[class*="price"]'
        ]
        
        for selector in price_selectors:
            elements = soup.select(selector)
            for elem in elements:
                text = elem.get_text().strip()
                try:
                    clean_text = re.sub(r'[^\d.,]', '', text)
                    if clean_text and '.' in clean_text:
                        price_val = float(clean_text.replace(',', ''))
                        if 0.01 <= price_val <= 10000:
                            print(f"âœ… í•´ì™¸ ê°€ê²© ë°œê²¬ ({selector}): ${price_val}")
                            if current_price == 0:
                                current_price = price_val
                except:
                    continue
        
        # ë°©ë²• 2: í…ìŠ¤íŠ¸ì—ì„œ ë‹¬ëŸ¬ ê°€ê²© ì°¾ê¸°
        if current_price == 0:
            dollar_texts = soup.find_all(string=re.compile(r'\$\d+\.\d+'))
            for text in dollar_texts:
                try:
                    price_match = re.search(r'\$(\d+\.\d+)', text)
                    if price_match:
                        price_val = float(price_match.group(1))
                        if 0.01 <= price_val <= 10000:
                            print(f"âœ… ë‹¬ëŸ¬ í…ìŠ¤íŠ¸ì—ì„œ ê°€ê²© ë°œê²¬: ${price_val}")
                            current_price = price_val
                            break
                except:
                    continue
        
        # ë³€ë™ë¥  íŒŒì‹±
        percent_texts = soup.find_all(string=re.compile(r'[+-]?\d+\.\d+%'))
        for text in percent_texts:
            try:
                percent_match = re.search(r'([+-]?\d+\.\d+)%', text)
                if percent_match:
                    change_percent = float(percent_match.group(1))
                    print(f"âœ… í•´ì™¸ ë³€ë™ë¥  ë°œê²¬: {change_percent}%")
                    break
            except:
                continue
        
        # ê²°ê³¼ ë°˜í™˜
        if current_price > 0:
            result = {
                'symbol': symbol,
                'name': name,
                'name_kr': name,
                'current_price': current_price,
                'change_percent': change_percent,
                'market': 'NASDAQ' if '.O' in successful_url else 'NYSE',
                'source': 'naver_world_parsing_fixed',
                'url_used': successful_url
            }
            
            print(f"âœ… í•´ì™¸ ì£¼ì‹ ìµœì¢… ê²°ê³¼: {result}")
            return result
        else:
            print(f"âŒ í•´ì™¸ ì£¼ì‹ ê°€ê²© íŒŒì‹± ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        print(f"âŒ í•´ì™¸ ì£¼ì‹ ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return None

def _validate_world_stock_page(soup: BeautifulSoup) -> bool:
    """í•´ì™¸ì£¼ì‹ í˜ì´ì§€ê°€ ìœ íš¨í•œ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸"""
    try:
        # ê°€ê²© ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
        price_indicators = [
            soup.find('span', class_='price'),
            soup.find('span', class_='num'),
            soup.select('.price_area .num'),
            soup.find_all(string=re.compile(r'\$\d+\.\d+')),
            soup.find_all(string=re.compile(r'\d+\.\d+'))
        ]
        
        for indicator in price_indicators:
            if indicator:
                return True
        
        # 404 í˜ì´ì§€ë‚˜ ì˜¤ë¥˜ í˜ì´ì§€ ì²´í¬
        error_texts = ['404', 'not found', 'í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤', 'error']
        page_text = soup.get_text().lower()
        
        for error_text in error_texts:
            if error_text in page_text:
                return False
        
        return True
        
    except Exception as e:
        print(f"âš ï¸ í˜ì´ì§€ ê²€ì¦ ì˜¤ë¥˜: {e}")
        return False

async def extract_stock_data_from_js(html_content: str, query: str):
    """JavaScript ë³€ìˆ˜ì—ì„œ ì‹¤ì‹œê°„ ì£¼ì‹ ë°ì´í„° ì¶”ì¶œ"""
    print(f"ğŸ” JavaScriptì—ì„œ ì£¼ì‹ ë°ì´í„° ì¶”ì¶œ: {query}")
    
    try:
        # 1. í˜„ì¬ ê°€ê²© ë°ì´í„° ì°¾ê¸°
        current_price = 0
        
        # closePrice íŒ¨í„´ ì°¾ê¸° (ê°€ì¥ ìµœì‹  ê°€ê²©)
        close_price_matches = re.findall(r'"closePrice":\s*([0-9.]+)', html_content)
        if close_price_matches:
            try:
                current_price = float(close_price_matches[-1])  # ë§ˆì§€ë§‰(ìµœì‹ ) ê°€ê²© ì‚¬ìš©
                print(f"âœ… closePriceì—ì„œ ë°œê²¬: ${current_price}")
            except:
                pass
        
        # currentPrice íŒ¨í„´ ì°¾ê¸° (ì‹¤ì‹œê°„ ê°€ê²©)
        if current_price == 0:
            current_price_matches = re.findall(r'"currentPrice":\s*([0-9.]+)', html_content)
            if current_price_matches:
                try:
                    current_price = float(current_price_matches[-1])  # ë§ˆì§€ë§‰(ìµœì‹ ) ê°€ê²© ì‚¬ìš©
                    print(f"âœ… currentPriceì—ì„œ ë°œê²¬: ${current_price}")
                except:
                    pass
        
        # 2. ì£¼ì‹ëª…ê³¼ ì‹¬ë³¼ ì°¾ê¸°
        stock_name = query
        stock_symbol = query
        
        # ë©”íƒ€ íƒœê·¸ì—ì„œ ì£¼ì‹ëª… ì°¾ê¸°
        meta_title_match = re.search(r'<meta property="og:title" content="([^"]*)', html_content)
        if meta_title_match:
            title = meta_title_match.group(1)
            if ' - ë„¤ì´ë²„í˜ì´ ì¦ê¶Œ' in title:
                stock_name = title.replace(' - ë„¤ì´ë²„í˜ì´ ì¦ê¶Œ', '').strip()
                print(f"âœ… ë©”íƒ€ íƒœê·¸ì—ì„œ ì£¼ì‹ëª… ë°œê²¬: {stock_name}")
        
        # JavaScript ë³€ìˆ˜ì—ì„œ ì‹¬ë³¼ ì°¾ê¸°
        symbol_matches = re.findall(r'"stockExchangeType"\s*:\s*"([^"]+)"', html_content)
        market = 'NASDAQ'
        if symbol_matches:
            market = symbol_matches[0]
            print(f"âœ… ê±°ë˜ì†Œ ì •ë³´ ë°œê²¬: {market}")
        
        # 3. ë³€ë™ë¥  ê³„ì‚° (ê°€ëŠ¥í•˜ë©´)
        change_percent = 0
        
        # ê°€ê²© ë°°ì—´ì—ì„œ ì „ì¼ ëŒ€ë¹„ ê³„ì‚°
        price_matches = re.findall(r'"closePrice":\s*([0-9.]+)', html_content)
        if len(price_matches) >= 2:
            try:
                current = float(price_matches[-1])
                previous = float(price_matches[-2])
                if previous > 0:
                    change_percent = ((current - previous) / previous) * 100
                    print(f"âœ… ë³€ë™ë¥  ê³„ì‚°: {change_percent:.2f}%")
            except:
                pass
        
        # 4. ê²°ê³¼ ë°˜í™˜
        if current_price > 0:
            result = {
                'symbol': stock_symbol,
                'name': stock_name,
                'name_kr': stock_name,
                'current_price': current_price,
                'change_percent': change_percent,
                'market': market,
                'source': 'naver_stock_search_js'
            }
            
            print(f"âœ… JavaScript íŒŒì‹± ìµœì¢… ê²°ê³¼: {result}")
            return result
        else:
            print(f"âŒ JavaScriptì—ì„œ ê°€ê²© ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        print(f"âŒ JavaScript íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return None

if __name__ == "__main__":
    print("ğŸš€ ë„¤ì´ë²„ ì‹¤ì‹œê°„ íŒŒì‹± ì„œë²„ ì‹œì‘...")
    print("ğŸ“ˆ ì£¼ì‹ ê²€ìƒ‰: http://localhost:8001/naver/stocks/search/ì‚¼ì„±ì „ì")
    print("ğŸ’± í™˜ìœ¨ ì¡°íšŒ: http://localhost:8001/naver/currency/rate/USD/KRW")
    uvicorn.run(app, host="0.0.0.0", port=8001) 